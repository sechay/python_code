{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees, Forests, and Ensembles\n",
    "\n",
    "![japanese maple](assets/trees/japanese-maple-2947680_640.jpg)\n",
    "\n",
    "(image: [pixabay](https://pixabay.com/en/japanese-maple-foliage-green-leaves-2947680/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics\n",
    "\n",
    "- Decision Trees\n",
    "- Ensemble Forests\n",
    "- Classification\n",
    "- Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where are we?\n",
    "\n",
    "(lost in the forest?)\n",
    "\n",
    "![spot the trees](assets/linear-regression/machine-learning-cheet-sheet.png)\n",
    "\n",
    "(image: [sas.com](https://www.sas.com/en_us/insights/analytics/machine-learning.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees\n",
    "- Classification: predicts a class\n",
    "- Regression: predicts a number\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "Advantanges:\n",
    "- Easy to visualize and understand\n",
    "- $O(log(N))$ prediction cost\n",
    "- Flexible for simple tasks: binary / multi-class classification, regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "Disadvantages:\n",
    "- Overfitting\n",
    "- Unbalanced dataset can cause biased trees\n",
    "- Instability: small changes in data can result in completely different tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ensemble Methods\n",
    "\n",
    "![ensemble](assets/trees/teamwork-2499638_960_720.jpg)\n",
    "\n",
    "(image: [pixabay](https://pixabay.com/en/teamwork-team-gear-board-chalk-2499638/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ensemble Methods\n",
    "\"Teaming up weaker models to create a stronger model\"\n",
    "\n",
    "- Random Forest\n",
    "- AdaBoost\n",
    "- Gradient Boosted Trees\n",
    "- etc\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Forests\n",
    "\n",
    "- Fits a few decision trees on subsets of the dataset, then averages the results\n",
    "  - Improves accuracy and reduces overfitting\n",
    "- Classifier: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "- Regressor: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AdaBoost\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/ensemble.html#adaboost\n",
    "- Fit a sequence of small decision trees on repeatedly modified versions of data\n",
    "  \n",
    "  - adjust weights on the training samples\n",
    "    - incorrectly predicted training sample => more weight\n",
    "    - correctly predicted sample => less weight\n",
    "    \n",
    "    \n",
    "- Combine predictions using sum or majority vote\n",
    "\n",
    "- \"Samples that were gotten wrong get more attention\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AdaBoost\n",
    "\n",
    "- Classifier: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "- Regressor: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Boosted Trees\n",
    "\n",
    "- Optimized using Gradient Descent\n",
    "- Better generalization\n",
    "- Classifier: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "- Regressor: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "![really?](assets/trees/blog_Gradient-Boosting-Image.png)\n",
    "\n",
    "(image: http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting: Concept\n",
    "\n",
    "1. Nth tree has some prediction error.\n",
    "\n",
    "2. Train the next (N+1)th tree to \"boost\" the model so that it can compensate for the gap (error) from the Nth tree. \n",
    "\n",
    "3. Add up the predictions from the all trees to fill up the gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Boosting: Concept\n",
    "\n",
    "1. Train first tree, measure training error (\"residuals\")\n",
    "$$F_1(x) = y$$\n",
    "2. Train second tree on the residuals, using dataset $\\big(x, y-F_1(x)\\big)$\n",
    "$$h_1(x) = y - F_1(x)$$\n",
    "3. Combine to get a better model\n",
    "$$F_2(x) = F_1(x) + h_1(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Boosting: Concept\n",
    "\n",
    "General formulation:\n",
    "$$F_{m+1}(x) = F_m(x) + h_m(x) = y$$\n",
    "\n",
    "Where $m$ is tuned by cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Boosting: Gradient Descent\n",
    "\n",
    "- Objective: minimize cost function: $L\\big(y, F(x)\\big)$\n",
    "- Apply Tree Boosting, but compute residuals from the **gradients of the cost function**\n",
    "- $n$ training examples $(x_1, ... x_n)$\n",
    "- Residual for the $i^{th}$ example, $m^{th}$ tree:\n",
    "\n",
    "$$r_{im} = -\\biggl[\\frac{\\partial{L\\big(y_i, F_{m-1}(x_i)\\big)}}{\\partial{F_{m-1}(x_i)}}\\biggr]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Boosting: Algorithm\n",
    "\n",
    "1. Compute residual using $F_{m-1}(x_i)$ and $y_i$\n",
    "2. Train decision tree $h_m(x)$, using dataset ${(x_i, r_{im})}$\n",
    "3. Compute update multiplier:\n",
    "$$\\gamma_m = \\underset{\\gamma}{\\arg \\min} \\sum^n_{i=1} L\\big(y, F_{m-1} + \\gamma h_{m}(x)\\big)$$\n",
    "4. Get next model using multiplier:\n",
    "$$F_m(x) = F_{m-1}(x) + \\gamma_mh_m(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### XGBoost\n",
    "\n",
    "eXtreme Gradient Boosting\n",
    "- A parallel, distributed gradient boosting library\n",
    "- https://github.com/dmlc/xgboost\n",
    "- https://xgboost.readthedocs.io/en/latest/model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "- General metrics for Classification and Regression\n",
    "- Decision Tree-specific metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision Tree-specific Metrics\n",
    "- Gini: gini impurity, which measures the quality of a split\n",
    "  - greater than 0: split needed\n",
    "  - 0: all cases fall in 1 category\n",
    "- Information gain / entropy\n",
    "  - pick the split with the highest information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workshop: Classification with Decision Trees\n",
    "\n",
    "Credits: http://scikit-learn.org/stable/modules/tree.html#classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "We'll be using Graphviz to visualize the decision tree after training it.\n",
    "\n",
    "Add this module to your `mldds02` conda environment:\n",
    "\n",
    "```\n",
    "conda install python-graphviz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goal\n",
    "\n",
    "Train and compare decision tree-based classifiers to predict the `sector` from research and development expenditure type, cost type, and expenditure amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "#### Research and Development Expenditure by Type of Cost\n",
    "\n",
    "https://data.gov.sg/dataset/research-and-development-expenditure-by-type-of-cost\n",
    "\n",
    "1. Download dataset from the above URL\n",
    "2. Extract the folder and note the path for use in `read_csv` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "1. Encode string labels to numbers\n",
    "2. Ensure dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>type_of_expenditure</th>\n",
       "      <th>type_of_cost</th>\n",
       "      <th>rnd_expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Capital Expenditure</td>\n",
       "      <td>Land, Buildings &amp; Other Structures</td>\n",
       "      <td>231.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Capital Expenditure</td>\n",
       "      <td>Vehicles, Plant, Machinery &amp; Equipment</td>\n",
       "      <td>670.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Researchers</td>\n",
       "      <td>1914.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Technicians</td>\n",
       "      <td>75.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Other Supporting Staff</td>\n",
       "      <td>134.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sector   type_of_expenditure  \\\n",
       "0  Private Sector   Capital Expenditure   \n",
       "1  Private Sector   Capital Expenditure   \n",
       "2  Private Sector  Manpower Expenditure   \n",
       "3  Private Sector  Manpower Expenditure   \n",
       "4  Private Sector  Manpower Expenditure   \n",
       "\n",
       "                             type_of_cost  rnd_expenditure  \n",
       "0      Land, Buildings & Other Structures           231.79  \n",
       "1  Vehicles, Plant, Machinery & Equipment           670.82  \n",
       "2                             Researchers          1914.63  \n",
       "3                             Technicians            75.70  \n",
       "4                  Other Supporting Staff           134.54  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:\\\\courses\\\\data\\\\trees\\\\research-and-development-expenditure-by-type-of-cost.csv',\n",
    "\n",
    "                 usecols=['sector', 'type_of_expenditure', 'type_of_cost', 'rnd_expenditure'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Label Encoding for Classification\n",
    "\n",
    "Training data needs to be numeric.\n",
    "\n",
    "To convert string labels to numbers, we will do something called \"label encoding\".\n",
    "\n",
    "There are multiple ways to do this: http://pbpython.com/categorical-encoding.html\n",
    "- Dummy columns\n",
    "- Integer labels\n",
    "\n",
    "For this dataset, we'll try assigning integer labels to each unique string value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>type_of_expenditure</th>\n",
       "      <th>type_of_cost</th>\n",
       "      <th>rnd_expenditure</th>\n",
       "      <th>sector_c</th>\n",
       "      <th>type_of_expenditure_c</th>\n",
       "      <th>type_of_cost_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Capital Expenditure</td>\n",
       "      <td>Land, Buildings &amp; Other Structures</td>\n",
       "      <td>231.79</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Capital Expenditure</td>\n",
       "      <td>Vehicles, Plant, Machinery &amp; Equipment</td>\n",
       "      <td>670.82</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Researchers</td>\n",
       "      <td>1914.63</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Technicians</td>\n",
       "      <td>75.70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Other Supporting Staff</td>\n",
       "      <td>134.54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Private Sector</td>\n",
       "      <td>Other Operating Expenditure</td>\n",
       "      <td>Other Operating Costs</td>\n",
       "      <td>2188.18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Government Sector</td>\n",
       "      <td>Capital Expenditure</td>\n",
       "      <td>Land, Buildings &amp; Other Structures</td>\n",
       "      <td>27.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Government Sector</td>\n",
       "      <td>Capital Expenditure</td>\n",
       "      <td>Vehicles, Plant, Machinery &amp; Equipment</td>\n",
       "      <td>30.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Government Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Researchers</td>\n",
       "      <td>304.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Government Sector</td>\n",
       "      <td>Manpower Expenditure</td>\n",
       "      <td>Technicians</td>\n",
       "      <td>33.21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sector          type_of_expenditure  \\\n",
       "0     Private Sector          Capital Expenditure   \n",
       "1     Private Sector          Capital Expenditure   \n",
       "2     Private Sector         Manpower Expenditure   \n",
       "3     Private Sector         Manpower Expenditure   \n",
       "4     Private Sector         Manpower Expenditure   \n",
       "5     Private Sector  Other Operating Expenditure   \n",
       "6  Government Sector          Capital Expenditure   \n",
       "7  Government Sector          Capital Expenditure   \n",
       "8  Government Sector         Manpower Expenditure   \n",
       "9  Government Sector         Manpower Expenditure   \n",
       "\n",
       "                             type_of_cost  rnd_expenditure  sector_c  \\\n",
       "0      Land, Buildings & Other Structures           231.79         2   \n",
       "1  Vehicles, Plant, Machinery & Equipment           670.82         2   \n",
       "2                             Researchers          1914.63         2   \n",
       "3                             Technicians            75.70         2   \n",
       "4                  Other Supporting Staff           134.54         2   \n",
       "5                   Other Operating Costs          2188.18         2   \n",
       "6      Land, Buildings & Other Structures            27.17         0   \n",
       "7  Vehicles, Plant, Machinery & Equipment            30.05         0   \n",
       "8                             Researchers           304.45         0   \n",
       "9                             Technicians            33.21         0   \n",
       "\n",
       "   type_of_expenditure_c  type_of_cost_c  \n",
       "0                      0               0  \n",
       "1                      0               5  \n",
       "2                      1               3  \n",
       "3                      1               4  \n",
       "4                      1               2  \n",
       "5                      2               1  \n",
       "6                      0               0  \n",
       "7                      0               5  \n",
       "8                      1               3  \n",
       "9                      1               4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "\n",
    "# encode sector from strings to integer labels\n",
    "df['sector_c'] = le1.fit_transform(df['sector'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "df['type_of_expenditure_c'] = le2.fit_transform(df['type_of_expenditure'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "df['type_of_cost_c'] = le3.fit_transform(df['type_of_cost'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Ensuring Balanced Dataset for Decision Tree Algorithms\n",
    "\n",
    "For decision trees, it is important to balance the dataset to reduce class bias.\n",
    "\n",
    "If a dataset contains too many samples of one sector (e.g. 'Private Sector', the tree will learn to pick that sector more frequently, which means it's no better than random selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Private Sector', 'Government Sector', 'Higher Education Sector',\n",
       "       'Public Research Institutes'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sector.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Government Sector', 'Higher Education Sector', 'Private Sector',\n",
       "       'Public Research Institutes'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    30\n",
       "2    30\n",
       "1    30\n",
       "0    30\n",
       "Name: sector_c, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect if a dataset is unbalanced\n",
    "df['sector_c'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We got lucky here with the dataset, as there are equal numbers of value_counts for each sector.\n",
    "\n",
    "Suppose we need to balance the dataset, we can use this technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60\n",
       "3    30\n",
       "2    30\n",
       "1    30\n",
       "Name: sector_c, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate an unbalanced dataset by replicating columns for sector_c=0\n",
    "\n",
    "df.loc[df.sector_c == 0]\n",
    "\n",
    "# make a copy so as not to affect our original df\n",
    "unbalanced_df = pd.concat([df, df.loc[df.sector_c == 0]], ignore_index=True)\n",
    "\n",
    "# show the unbalanced dataset, sector_c = 0 will have double the number of entries\n",
    "unbalanced_df['sector_c'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    30\n",
       "2    30\n",
       "1    30\n",
       "0    30\n",
       "Name: sector_c, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_groups = unbalanced_df.groupby('sector_c')\n",
    "\n",
    "# use pandas.DataFrame.sample to create a DataFrame\n",
    "# where all sector groups are re-sampled to the smallest sized group\n",
    "balanced_df = sector_groups.apply(lambda x: x.sample(sector_groups.size().min())).\\\n",
    "    reset_index(drop=True)\n",
    "\n",
    "# show the balanced_df, all sectors are balanced\n",
    "balanced_df['sector_c'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Select Features\n",
    "\n",
    "We'll now break our DataFrame into data and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = df[['rnd_expenditure', 'type_of_expenditure_c', 'type_of_cost_c']]\n",
    "target = df['sector_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnd_expenditure</th>\n",
       "      <th>type_of_expenditure_c</th>\n",
       "      <th>type_of_cost_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670.82</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1914.63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.70</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rnd_expenditure  type_of_expenditure_c  type_of_cost_c\n",
       "0           231.79                      0               0\n",
       "1           670.82                      0               5\n",
       "2          1914.63                      1               3\n",
       "3            75.70                      1               4\n",
       "4           134.54                      1               2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: sector_c, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Train the Decision Tree Classifier\n",
    "\n",
    "1. Shuffle and split the data set into train and test\n",
    "2. Train a `DecisionTreeClassifier`\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(train_X_scaled, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 1, 2, 0, 3, 0, 0, 3, 3, 1, 1, 3, 3, 0, 1, 0, 0, 2, 3, 0,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.predict(test_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Probabilities are expressed as a\n",
    "# fraction of samples of the same class in a leaf\n",
    "#print(dtc.decision_path(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Evaluate Metrics: Classification Accuracy\n",
    "\n",
    "Since this is a classification task, the metrics we used for Logistic Regression also apply here, such as\n",
    "- Precision, recall\n",
    "- Confusion matrix\n",
    "- Accuracy\n",
    "\n",
    "References:\n",
    "- http://scikit-learn.org/stable/modules/classes.html#classification-metrics\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.17      0.15         6\n",
      "          1       0.40      0.40      0.40        10\n",
      "          2       0.80      0.67      0.73         6\n",
      "          3       0.38      0.38      0.38         8\n",
      "\n",
      "avg / total       0.42      0.40      0.41        30\n",
      "\n",
      "[[1 3 1 1]\n",
      " [3 4 0 3]\n",
      " [1 0 4 1]\n",
      " [2 3 0 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pred_y = dtc.predict(test_X_scaled)\n",
    "\n",
    "print(classification_report(test_y, pred_y))\n",
    "\n",
    "cm = confusion_matrix(test_y, pred_y)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Visualizing the Decision Tree\n",
    "\n",
    "We'll visualize the learned decision tree using graphviz, to see what type of rules it has learnt from the training data.\n",
    "\n",
    "https://graphviz.readthedocs.io/en/stable/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9428cf8a0105>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvisualize_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitted_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "def visualize_tree(fitted_tree, feature_names, target_names, filename):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        fitted_tree: the fitted decision tree. If using ensemble methods\n",
    "            pick the first estimator using model.estimators[0]\n",
    "        feature_names: array containing the feature names\n",
    "        target_names: array containing the target labels\n",
    "        filename: the filename to save the .dot file\n",
    "    \"\"\"\n",
    "    export_graphviz(fitted_tree, out_file=filename,\n",
    "                    feature_names=feature_names,\n",
    "                    class_names=target_names,\n",
    "                    filled=True, rounded=True)\n",
    "\n",
    "    source = graphviz.Source.from_file(filename)\n",
    "    source.render(view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/research-and-development-expenditure-by-type-of-cost/govt_sector_by_expenditure_tree.dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-4e7cf77c9ef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/research-and-development-expenditure-by-type-of-cost/govt_sector_by_expenditure_tree.dot'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mvisualize_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-aae37cc3a009>\u001b[0m in \u001b[0;36mvisualize_tree\u001b[1;34m(fitted_tree, feature_names, target_names, filename)\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mclass_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     filled=True, rounded=True)\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\mldds02\\lib\\site-packages\\sklearn\\tree\\export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                 \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/research-and-development-expenditure-by-type-of-cost/govt_sector_by_expenditure_tree.dot'"
     ]
    }
   ],
   "source": [
    "feature_names=['rnd_expenditure', 'type_of_expenditure', 'type_of_cost']\n",
    "\n",
    "#target_names=df['sector'].unique() ???\n",
    "target_names = le1.classes_ # label encoder's order\n",
    "\n",
    "filename = '../data/research-and-development-expenditure-by-type-of-cost/govt_sector_by_expenditure_tree.dot'\n",
    "\n",
    "visualize_tree(dtc, feature_names, target_names, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Exercise - Decision Tree Classification using Entropy\n",
    "\n",
    "Repeat the steps above to:\n",
    "1. Train a decision tree using the 'entropy' criteria using the training set\n",
    "2. Evaluate the classification metrics\n",
    "3. Visualize the decision tree\n",
    "\n",
    "Which criteria performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Visualizing Decision Tree Surfaces\n",
    "\n",
    "Here's a neat trick to try in lieu of what we saw with clustering.\n",
    "\n",
    "Credits: http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html\n",
    "import numpy as np\n",
    "\n",
    "def plot_decision_surface(classifier, n_classes, X, y, title):\n",
    "    \"\"\"Plots a decision surface using pair-wise combination\n",
    "    of features\n",
    "    Args:\n",
    "        classifier - the decision tree classifier\n",
    "        n_classes - the number of classes\n",
    "        X - the data\n",
    "        y - the labels\n",
    "        title - the plot title\n",
    "    \"\"\"\n",
    "    plot_colors = 'ryb'\n",
    "    plot_step = 0.02\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for pairidx, pair in enumerate([[0, 1], [0, 2], [1, 2]]):\n",
    "        # We only take the two corresponding features\n",
    "        x = X.values[:, pair]\n",
    "\n",
    "        clf = classifier.fit(x, y)\n",
    "\n",
    "        # Plot the decision boundary\n",
    "        plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "        x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "        y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                             np.arange(y_min, y_max, plot_step))\n",
    "        plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "        plt.xlabel(feature_names[pair[0]])\n",
    "        plt.ylabel(feature_names[pair[1]])\n",
    "\n",
    "        # Plot the training points\n",
    "        for i, color in zip(range(n_classes), plot_colors):\n",
    "            idx = np.where(y == i)\n",
    "            plt.scatter(x[idx, 0], x[idx, 1], c=color, label=target_names[i],\n",
    "                        cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.legend(loc='lower right', borderpad=0, handletextpad=0)\n",
    "    plt.axis(\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(target.unique())\n",
    "plot_decision_surface(DecisionTreeClassifier(), n_classes, train_X, train_y,\n",
    "                      \"Decision surface of a Decision Tree classifier using paired features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# To get the category label mapping\n",
    "df[['type_of_expenditure', 'type_of_expenditure_c']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df[['type_of_cost', 'type_of_cost_c']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df[['sector', 'sector_c']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Random Forest Classifier with GridSearchCV\n",
    "\n",
    "Now that we have our baseline tree, the next step is to try an ensemble method, such as Random Forest.\n",
    "\n",
    "Let's also maximize our chances of getting the best model by doing Grid Search cross-validation.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Use GridSearchCV to select the optimum hyperparameters\n",
    "gs_rfc = GridSearchCV(RandomForestClassifier(), {'max_depth': [2, 4, 6, 8],\n",
    "                                                 'n_estimators': [5, 10, 20, 30]},\n",
    "                      verbose=1)\n",
    "\n",
    "gs_rfc.fit(train_X, train_y)\n",
    "\n",
    "# select the best estimator\n",
    "print('Best score:', gs_rfc.best_score_)\n",
    "print('Best parameters:', gs_rfc.best_params_)\n",
    "\n",
    "# predict\n",
    "pred_y = gs_rfc.predict(test_X)\n",
    "\n",
    "# evaluation metrics\n",
    "print(classification_report(test_y, pred_y))\n",
    "cm = confusion_matrix(test_y, pred_y)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gs_rfc.best_estimator_.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the first tree in the forest\n",
    "rfc = gs_rfc.best_estimator_\n",
    "\n",
    "visualize_tree(rfc.estimators_[0], feature_names, target_names,\n",
    "               '../data/research-and-development-expenditure-by-type-of-cost/govt_sector_by_expenditure_rf_first.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the last tree in the forest\n",
    "visualize_tree(rfc.estimators_[-1], feature_names, target_names,\n",
    "               '../data/research-and-development-expenditure-by-type-of-cost/govt_sector_by_expenditure_rf_last.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the decision surface for pair-wise features, using\n",
    "# the best estimator found by GridSearchCV\n",
    "best_n_estimators = n_estimators=gs_rfc.best_params_['n_estimators']\n",
    "best_max_depth = n_estimators=gs_rfc.best_params_['max_depth']\n",
    "\n",
    "plot_decision_surface(RandomForestClassifier(n_estimators=best_n_estimators,\n",
    "                                             max_depth=best_max_depth),\n",
    "                      n_classes, train_X, train_y,\n",
    "                      \"Decision surface of a Random Forest classifier using paired features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## XGBoost Classifier with GridSearchCV\n",
    " \n",
    "Finally, let's try XGBoost on our dataset, to see how well it does.\n",
    "\n",
    "### Setup\n",
    "\n",
    "XGBoost is a separate library from sklearn (https://xgboost.readthedocs.io/en/latest/build.html)\n",
    "\n",
    "```\n",
    "conda install -c anaconda py-xgboost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### XGBoost and Scikit-learn\n",
    "\n",
    "XGBoost has its own API, but includes an sklearn wrapper for convenience.\n",
    "\n",
    "https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_examples.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Use GridSearchCV to select the optimum hyperparameters\n",
    "gs_xgb = GridSearchCV(xgb.XGBClassifier(), {'max_depth': [2, 4, 6, 8],\n",
    "                                            'n_estimators': [5, 10, 20, 30]},\n",
    "                      verbose=1)\n",
    "\n",
    "gs_xgb.fit(train_X, train_y)\n",
    "\n",
    "# select the best estimator\n",
    "print('Best score:', gs_xgb.best_score_)\n",
    "print('Best parameters:', gs_xgb.best_params_)\n",
    "\n",
    "# predict\n",
    "pred_y = gs_xgb.predict(test_X)\n",
    "\n",
    "# evaluation metrics\n",
    "print(classification_report(test_y, pred_y))\n",
    "cm = confusion_matrix(test_y, pred_y)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Workshop: Regression with Decision Trees\n",
    "\n",
    "In this workshop, we will apply decision tree-related algorithms to a multi-variate linear regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Goal\n",
    "\n",
    "Train a regression model to predict the `Lifetime Post Total Reach` of a Facebook post to seven input features (category, page total likes, type, month, hour, weekday, paid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "#### Facebook metrics Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Facebook+metrics\n",
    "\n",
    "The data is related to posts' published during the year of 2014 on the Facebook's page of a renowned cosmetics brand.\n",
    "\n",
    "1. Download dataset from the above URL\n",
    "2. Extract the folder and note the path for use in read_csv below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../data/Facebook_metrics/dataset_Facebook.csv',\n",
    "                 delimiter=';',\n",
    "                 usecols=['Page total likes', 'Type', 'Category',\n",
    "                         'Post Month', 'Post Weekday', 'Post Hour', 'Paid',\n",
    "                         'Lifetime Post Total Reach'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "### Handle NaN values\n",
    "\n",
    "Check for NaN values and decide what to do with them.\n",
    "\n",
    "### Convert string columns\n",
    "\n",
    "There are two options for the `Type` column.\n",
    "  1. Convert to dummy columns.\n",
    "  2. Encode the labels to numbers.\n",
    "\n",
    "Either option is fine because the number of labels is small (4). Since we've demonstrated label encoding, we'll try the dummy column approach.\n",
    "\n",
    "### Balance dataset\n",
    "\n",
    "This is a regression task, so we don't need to balance the `Lifetime Post Total Reach` output, because it is a continuous variable.\n",
    "- Instead, we'll check that the discrete columns (`Type`, `Category`, `Paid`) values are balanced.\n",
    "- It's less critical, but a good idea to also check the `Post Month`, `Post Weekday` and `Post Hour` columns, just in case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle NaN values\n",
    "\n",
    "Check for NaN values and decide what to do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Convert string columns\n",
    "\n",
    "Convert `Type` to dummy columns and append to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_type_dummies = pd.get_dummies(df['Type'])\n",
    "df_type_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Append to existing dataset\n",
    "df = pd.concat([df, df_type_dummies], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Balance dataset\n",
    "\n",
    "Check that these discrete columns are balanced\n",
    "- `Type`\n",
    "- `Category`\n",
    "- `Paid`\n",
    "\n",
    "Optionally, check that these discrete columns are balanced\n",
    "- `Post Month`\n",
    "- `Post Weekday`\n",
    "- `Post Hour`\n",
    "\n",
    "Balanced means that the counts for each discrete values are not overly biased to one or two values. As a rule of thumb, overly means 10x or larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Detect if the `Type` column is balanced\n",
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Instead of dropping all the columns, let's reduce just the `Photo` rows by a random sample of 90 entries\n",
    "num_photo_rows = 90\n",
    "photos_df = df.loc[df.Type == 'Photo']\n",
    "\n",
    "indices_to_keep = photos_df.sample(num_photo_rows).index # random sample the indices\n",
    "indices_to_drop = list(set(photos_df.index) - set(indices_to_keep))\n",
    "\n",
    "balanced_df = df.drop(df.index[indices_to_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df['Paid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode\n",
    "type_le = LabelEncoder()\n",
    "balanced_df.Type = type_le.fit_transform(balanced_df.Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Select Features\n",
    "\n",
    "Select the features X and y from `balanced_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_df.loc[:, balanced_df.columns != 'Lifetime Post Total Reach']\n",
    "y = balanced_df['Lifetime Post Total Reach']\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Train the Decision Tree Regressor\n",
    "\n",
    "1. Shuffle and split the data set into train and test\n",
    "2. Train a `DecisionTreeRegressor`\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "train_X_scaled = X_scaler.fit_transform(train_X)\n",
    "test_X_scaled = X_scaler.transform(test_X)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "train_y_scaled = y_scaler.fit_transform(train_y.values.reshape(-1, 1))\n",
    "test_y_scaled = y_scaler.transform(test_y.values.reshape(-1, 1))\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(train_X_scaled, train_y_scaled)\n",
    "pred_y_scaled = dtr.predict(test_X_scaled)\n",
    "\n",
    "print('MSE', mean_squared_error(test_y_scaled, pred_y_scaled),\n",
    "      'R2', r2_score(test_y_scaled, pred_y_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you want to silence the warning about int64, you can use something like this to convert to int32:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.astype.html\n",
    "    \n",
    "```\n",
    "df['Page total likes'] = df['Page total likes'].astype('int32')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Evaluate Metrics: Regression\n",
    "\n",
    "We'll now plot the learning curve for regression to see how well the decision tree performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(axis, title, tr_sizes, tr_scores, val_scores):\n",
    "    \"\"\"Plots the learning curve for a training session\n",
    "    Arg:\n",
    "        axis: axis to plot\n",
    "        title: plot title\n",
    "        tr_sizes: sizes of the training set\n",
    "        tr_scores: training scores\n",
    "        val_scores: validation scores\n",
    "    \"\"\"\n",
    "    tr_scores_mean = np.mean(tr_scores, axis=1)\n",
    "    tr_scores_std = np.std(tr_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    val_scores_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    axis.fill_between(tr_sizes, tr_scores_mean - tr_scores_std,\n",
    "                    tr_scores_mean + tr_scores_std, alpha=0.1,\n",
    "                    color=\"r\")\n",
    "    axis.fill_between(tr_sizes, val_scores_mean - val_scores_std,\n",
    "                    val_scores_mean + val_scores_std, alpha=0.1, color=\"g\")\n",
    "    axis.plot(tr_sizes, tr_scores_mean, 'o-', color=\"r\",\n",
    "            label=\"Training score\")\n",
    "    axis.plot(tr_sizes, val_scores_mean, 'o-', color=\"g\",\n",
    "            label=\"Cross-validation score\")\n",
    "    axis.set(title=title,\n",
    "           xlabel='Training examples',\n",
    "           ylabel='R2 Scores')\n",
    "    axis.grid()\n",
    "    axis.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the learning curve for decision tree classifier, using 3-fold Cross Validation\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    DecisionTreeRegressor(random_state=42), train_X, train_y,\n",
    "    random_state=42)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "plot_learning_curve(ax, 'Learning Curve: Decision Tree Regressor',\n",
    "                    train_sizes, train_scores, validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The Training R2 Score is constant. Can you think of a reason why?\n",
    "\n",
    "hint: consider how a decision tree would be created on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Validation R2 score isn't very good.\n",
    "\n",
    "Ways to improve:\n",
    "- Try Random Forest or XGBoost (typically will perform better)\n",
    "- Use a non-decision tree algorithm (Linear Regression, anyone?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Visualizing the Decision Tree\n",
    "\n",
    "Finally, we'll visualize the decision tree.\n",
    "\n",
    "This tree will look very complicated, because:\n",
    "1. There are many features\n",
    "2. We didn't place any limits on max_depth (which we should to make the tree more robust and less likely to overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = list(balanced_df.columns)\n",
    "feature_names.remove('Lifetime Post Total Reach')\n",
    "target_names = 'Lifetime Post Total Reach'\n",
    "\n",
    "filename = '../data/Facebook_metrics/facebook_likes_regressor.dot'\n",
    "\n",
    "visualize_tree(dtr, feature_names, target_names, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Optional Exercises\n",
    "\n",
    "This is a loooong workshop, but if you desire to learn more about Decision Trees, try the following:\n",
    "\n",
    "1. XGBoost regression\n",
    " - Replace `DecisionTreeRegressor()` with `xgb.Regressor()` with optional `GridSearchCV()`\n",
    " - https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_examples.py\n",
    " \n",
    "2. Random Forest Regressor\n",
    " - Replace `DecisionTreeRegressor()` with `RandomForestRegressor()` with optional `GridSearchCV()`\n",
    "\n",
    "3. Try other Decision Tree algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "autolaunch": false,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

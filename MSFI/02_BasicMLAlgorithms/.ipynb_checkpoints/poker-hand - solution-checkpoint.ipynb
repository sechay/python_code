{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification - Predict the Poker Hand\n",
    "\n",
    "Dataset:\n",
    "https://archive.ics.uci.edu/ml/datasets/Poker+Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset observations\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand.names\n",
    "\n",
    "- 10 classes\n",
    "- 1 million test samples\n",
    "- missing values: None\n",
    "- classes are not balanced (some poker hands are rare)\n",
    "- separate test dataset from train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "Data Gathering\n",
    "1. read_csv for both training and test set\n",
    "\n",
    "Data Transformation\n",
    "2. transform dataframe\n",
    "3. PCA to plot (for classification)\n",
    "4. shuffle training set (train test split not necessary as there is a separate test set)\n",
    "5. (scaling is optional because the column values are all similar)\n",
    "\n",
    "Training\n",
    "6. Train a Logistic Regression model\n",
    "7. Train a Logistic Regression model with SGD\n",
    "\n",
    "Validation\n",
    "8. metrics\n",
    "9. learning curve\n",
    "10. predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "1. read_csv for both training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'D:/tmp/poker-hand/poker-hand-training-true.data' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fc65460c219a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df = pd.read_csv('D:/tmp/poker-hand/poker-hand-training-true.data',\n\u001b[1;32m----> 2\u001b[1;33m                  names=['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5', 'CLASS'])\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\mldds02\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\mldds02\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\mldds02\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\mldds02\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\mldds02\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'D:/tmp/poker-hand/poker-hand-training-true.data' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\courses\\\\data\\\\poker-hand\\\\poker-hand-training-true.data',\n",
    "                 names=['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5', 'CLASS'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('D:/tmp/poker-hand/poker-hand-testing.data',\n",
    "                      names=['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5', 'CLASS'])\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation (Estimated time: 30 min)\n",
    "2. transform dataframe\n",
    "3. PCA to plot (for classification)\n",
    "4. shuffle training set (train test split not necessary as there is a separate test set)\n",
    "5. (scaling is optional because the column values are all similar)\n",
    "\n",
    "```\n",
    "# How to shuffle a pandas DataFrame\n",
    "df_shuffled = df.sample(frac=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: Nothing in hand; not a recognized poker hand \n",
    "# 1: One pair; one pair of equal ranks within five cards\n",
    "# 2: Two pairs; two pairs of equal ranks within five cards\n",
    "# 3: Three of a kind; three equal ranks within five cards\n",
    "# 4: Straight; five cards, sequentially ranked with no gaps\n",
    "# 5: Flush; five cards with the same suit\n",
    "# 6: Full house; pair + different rank three of a kind\n",
    "# 7: Four of a kind; four equal ranks within five cards\n",
    "# 8: Straight flush; straight + flush\n",
    "# 9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush\n",
    "\n",
    "labels = np.array([[0, 'nothing'], [1, 'one pair'],\n",
    "          [2, 'two pair'], [3, '3 of a kind'],\n",
    "          [4, 'straight'], [5, 'flush'],\n",
    "          [6, 'full house'], [7, '4 of a kind'],\n",
    "          [8, 'straight flush'], [9, 'royal flush']])\n",
    "\n",
    "\n",
    "X_train = df.loc[:, 'S1':'C5']\n",
    "y_train = df.loc[:, 'CLASS']\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_2d = pca.fit_transform(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "for value in y_train.unique():\n",
    "#for value in [9, 8, 1, 0, 4, 3, 2, 5, 6, 7]:\n",
    "#for value in [9, 8, 4, 3]:\n",
    "    ax.scatter(X_train_2d[y_train==value][:, 0],\n",
    "               X_train_2d[y_train==value][:, 1],\n",
    "               label=labels[value, 1],\n",
    "               cmap=plt.cm.plasma)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a subset of samples\n",
    "density = .25\n",
    "df_subset = df.sample(frac=density, random_state=42)\n",
    "\n",
    "X_train_subset = df_subset.loc[:, 'S1':'C5']\n",
    "y_train_subset = df_subset.loc[:, 'CLASS']\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_subset_2d = pca.fit_transform(X_train_subset)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "for value in y_train.unique():    \n",
    "    ax.scatter(X_train_subset_2d[y_train_subset==value][:, 0],\n",
    "               X_train_subset_2d[y_train_subset==value][:, 1],\n",
    "               label=labels[value, 1],\n",
    "               cmap=plt.cm.plasma)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-d PCA\n",
    "# plot a subset of samples\n",
    "density = .25\n",
    "df_subset = df.sample(frac=density, random_state=42)\n",
    "\n",
    "X_train_subset = df_subset.loc[:, 'S1':'C5']\n",
    "y_train_subset = df_subset.loc[:, 'CLASS']\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "X_train_subset_1d = pca.fit_transform(X_train_subset)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(X_train_subset_1d, y_train_subset)\n",
    "ax.set_title('1D PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to shuffle a pandas DataFrame\n",
    "df_shuffled = df.sample(frac=1)\n",
    "\n",
    "X_train = df_shuffled.loc[:, 'S1':'C5']\n",
    "y_train = df_shuffled.loc[:, 'CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.loc[:, 'S1':'C5']\n",
    "y_test = df_test.loc[:, 'CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "6. logistic regression\n",
    "7. SGD logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state=42)\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "pred_logistic = logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_bal = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logistic_bal.fit(X_train, y_train)\n",
    "\n",
    "pred_logistic_bal = logistic_bal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "pred_sgd = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_bal = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, class_weight='balanced')\n",
    "sgd_bal.fit(X_train, y_train)\n",
    "\n",
    "pred_sgd_bal = sgd_bal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "baseline = DummyClassifier()\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "pred_baseline = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "8. metrics\n",
    "9. learning curve\n",
    "10. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Logistic Regresion:')\n",
    "print(classification_report(y_test, pred_logistic))\n",
    "print('Logistic Regresion (balanced):')\n",
    "print(classification_report(y_test, pred_logistic_bal))\n",
    "\n",
    "print('SGD:')\n",
    "print(classification_report(y_test, pred_sgd))\n",
    "print('SGD (balanced):')\n",
    "print(classification_report(y_test, pred_sgd_bal))\n",
    "\n",
    "print('Baseline:')\n",
    "print(classification_report(y_test, pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_logistic = confusion_matrix(y_test, pred_logistic)\n",
    "cm_sgd = confusion_matrix(y_test, pred_sgd)\n",
    "cm_baseline = confusion_matrix(y_test, pred_baseline)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 30))\n",
    "ax = axes.flatten()\n",
    "\n",
    "# annotate cells with ticks\n",
    "sns.heatmap(cm_logistic, annot=True, ax=ax[0])\n",
    "sns.heatmap(cm_sgd, annot=True, ax=ax[1])\n",
    "sns.heatmap(cm_baseline, annot=True, ax=ax[2])\n",
    "\n",
    "print(cm_logistic)\n",
    "print(cm_sgd)\n",
    "print(cm_baseline)\n",
    "\n",
    "tick_labels = labels[:, 0]\n",
    "\n",
    "ax[0].set(xlabel='Predicted labels', ylabel='True labels', title='Confusion Matrix (Logistic Regression)') \n",
    "ax[0].xaxis.set_ticklabels(tick_labels)\n",
    "ax[0].yaxis.set_ticklabels(tick_labels)\n",
    "\n",
    "ax[1].set(xlabel='Predicted labels', ylabel='True labels', title='Confusion Matrix (Logistic Regression using SGD)'); \n",
    "ax[1].xaxis.set_ticklabels(tick_labels)\n",
    "ax[1].yaxis.set_ticklabels(tick_labels)\n",
    "\n",
    "ax[2].set(xlabel='Predicted labels', ylabel='True labels', title='Confusion Matrix (Baseline)'); \n",
    "ax[2].xaxis.set_ticklabels(tick_labels)\n",
    "ax[2].yaxis.set_ticklabels(tick_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Feature Extraction (from Kaggle)\n",
    "\n",
    "https://www.kaggle.com/c/poker-rule-induction/discussion/11177\n",
    "\n",
    "```\n",
    "Extract these features:\n",
    "\n",
    "- flush (1 or 0 boolean)\n",
    "\n",
    "- kind1 1 through 5 , number of most frequent card (e.g. 4 means 4 of a kind, 3 could be 3 of a kind or full house, 2 is 2 of a kind or 2 pair, etc.,  1 means, straight or nothing)\n",
    "\n",
    "- kind2 number of second-most frequent card, so if kind1=3 and kind2=2, full house, kind1=2, kind2=1, then one pair\n",
    "\n",
    "- high card (1 considered high if it occurs --yeah, concession to poker and other card games)\n",
    "\n",
    "- low card (needed to distinguish royal flush from ace 2 3 4 5)\n",
    "\n",
    "- straight (1 or 0 boolean)\n",
    "```\n",
    "\n",
    "Reference code:\n",
    "https://github.com/tdvance/kaggle_submissions/blob/master/poker/dataPrep.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the code to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(l):\n",
    "    h={}\n",
    "    for x in l:\n",
    "        if x in h:\n",
    "            h[x]+=1\n",
    "        else:\n",
    "            h[x] = 1\n",
    "    return h\n",
    "\n",
    "def hOfH(l, size=None):\n",
    "    h = histogram(l)\n",
    "    h = histogram(dict.values(h))\n",
    "    result = list(dict.values(h))\n",
    "    result.sort(reverse=True)\n",
    "    if(size is not None):\n",
    "        while(len(result)<size):\n",
    "            result += [0]\n",
    "        while len(result) > size:\n",
    "            result.pop()\n",
    "    return result\n",
    "\n",
    "def handToFeatures(hand):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    suits = [hand[0], hand[2], hand[4], hand[6], hand[8]]\n",
    "    ranks = [hand[1], hand[3], hand[5], hand[7], hand[9]]\n",
    "    sh = hOfH(suits, 4)\n",
    "\n",
    "    flush = int(sh[0] == 1 and sh[1] == 0)\n",
    "\n",
    "    h = list(dict.values(histogram(ranks)))\n",
    "    h.sort(reverse=True)\n",
    "    kind1 = h[0]\n",
    "    kind2 = h[1]\n",
    "\n",
    "    ranks.sort()\n",
    "    if(1 in ranks):\n",
    "        high = 1\n",
    "        low = ranks[0]\n",
    "        if low == 1:\n",
    "            low = ranks[1]\n",
    "    else:\n",
    "        high = ranks[-1]\n",
    "        low = ranks[0]\n",
    "\n",
    "    normalized = [(r - low + 13)%13 for r in ranks]\n",
    "    normalized.sort()\n",
    "    straight = int(normalized[-1]==4)\n",
    "\n",
    "    return [flush, kind1, kind2, high, low, straight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test the code first, before making any changes\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0, :10].values)\n",
    "\n",
    "print(handToFeatures(df.iloc[0, :10].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just the features (ignoring the class)\n",
    "df_original_features = df.iloc[:, :10]\n",
    "\n",
    "df_original_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose a new dataframe with the new features\n",
    "# apply the transformation per row\n",
    "# (confusingly, axis=1 means per row for pandas.DataFrame.apply())\n",
    "\n",
    "df_new_features = df_original_features.apply(handToFeatures, axis=1)\n",
    "\n",
    "df_new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem with the above dataframe is that it's a Series with nested lists\n",
    "# we need it to be 6 columns\n",
    "\n",
    "print(type(df_new_features))\n",
    "\n",
    "print(df_new_features.iloc[0]) # returns a list - we want 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list into columns, and add column names too\n",
    "df_new_features = pd.DataFrame(df_new_features.values.tolist(),\n",
    "                              columns=['flush', 'most_frequent', '2nd_most_frequent', 'high_card', 'low_card', 'straight'],\n",
    "                              index=df_new_features.index)\n",
    "\n",
    "df_new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tack on the class so that we can shuffle the X and y values together\n",
    "\n",
    "df_new_features['CLASS'] = df['CLASS']\n",
    "df_new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.to_csv('C:\\\\courses\\\\data\\\\poker-hand-kaggleSolution\\\\kaggle_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('C:\\\\courses\\\\data\\\\poker-hand-kaggleSolution\\\\kaggle_train.csv')\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same procedure for test\n",
    "\n",
    "# apply() can take a while to run through 1 million rows\n",
    "%time df_new_features_test = df_test.iloc[:, :10].apply(handToFeatures, axis=1)\n",
    "\n",
    "df_new_features_test = pd.DataFrame(df_new_features_test.values.tolist(),\n",
    "                                    columns=['flush', 'most_frequent', '2nd_most_frequent', 'high_card', 'low_card', 'straight'],\n",
    "                                    index=df_new_features_test.index)\n",
    "\n",
    "df_new_features_test['CLASS'] = df_test['CLASS']\n",
    "df_new_features_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features_test.to_csv('C:\\\\courses\\\\data\\\\poker-hand-kaggleSolution\\\\kaggle_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_test = pd.read_csv('C:\\\\courses\\\\data\\\\poker-hand-kaggleSolution\\\\kaggle_test.csv')\n",
    "df_2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([[0, 'nothing'], [1, 'one pair'],\n",
    "          [2, 'two pair'], [3, '3 of a kind'],\n",
    "          [4, 'straight'], [5, 'flush'],\n",
    "          [6, 'full house'], [7, '4 of a kind'],\n",
    "          [8, 'straight flush'], [9, 'royal flush']])\n",
    "\n",
    "\n",
    "X_train = df_new_features.loc[:, 'flush':'straight']\n",
    "y_train = df_new_features.loc[:, 'CLASS']\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_2d = pca.fit_transform(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "for value in y_train.unique():\n",
    "    ax.scatter(X_train_2d[y_train==value][:, 0],\n",
    "               X_train_2d[y_train==value][:, 1],\n",
    "               label=labels[value, 1],\n",
    "               cmap=plt.cm.plasma)\n",
    "ax.set_title('2D PCA (new features)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D PCA\n",
    "pca = PCA(n_components=1)\n",
    "X_train_1d = pca.fit_transform(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(X_train_1d, y_train)\n",
    "ax.set_title('1D PCA (new features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle, train, etc.\n",
    "\n",
    "df_shuffled = df_new_features.sample(frac=1)\n",
    "X_train = df_shuffled.loc[:, 'flush':'straight']\n",
    "y_train = df_shuffled.loc[:, 'CLASS']\n",
    "\n",
    "X_test = df_new_features_test.loc[:, 'flush':'straight']\n",
    "y_test = df_new_features_test.loc[:, 'CLASS']\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "print(X_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state=42)\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "pred_logistic = logistic.predict(X_test)\n",
    "print(classification_report(y_test, pred_logistic))\n",
    "print(confusion_matrix(y_test, pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
